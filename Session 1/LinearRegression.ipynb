{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## 1. Normalize data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_add_ones(X):\n",
    "    X = np.array(X)\n",
    "    X_max = np.array([[np.amax(X[:, column_id])\n",
    "                    for column_id in range(X.shape[1])]\n",
    "                    for _ in range(X.shape[0])])\n",
    "    X_min = np.array([[np.amin(X[:, column_id])\n",
    "                    for column_id in range(X.shape[1])]\n",
    "                    for _ in range(X.shape[0])])\n",
    "    X_normalized = (X - X_min) / (X_max - X_min)\n",
    "    ones = np.array([[1] for _ in range(X_normalized.shape[0])])\n",
    "    return np.column_stack((ones, X_normalized))"
   ]
  },
  {
   "source": [
    "## 2. Create RidgeRegression class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X_train, Y_train, LAMBDA):\n",
    "        assert len(X_train.shape) == 2 and X_train.shape[0] == Y_train.shape[0]\n",
    "        W = np.linalg.inv(\n",
    "            X_train.transpose().dot(X_train) +\n",
    "            LAMBDA * np.identity(X_train.shape[1])\n",
    "        ).dot(X_train.transpose()).dot(Y_train)\n",
    "        return W\n",
    "\n",
    "    def fit_gradient_descent(self, X_train, Y_train, LAMBDA, learning_rate, max_num_epoch=100, batch_size=128):\n",
    "        W = np.random.randn(X_train.shape[1])\n",
    "        last_loss = 10e+8\n",
    "        for ep in range(max_num_epoch):\n",
    "            arr = np.array(range(X_train.shape[0]))\n",
    "            np.random.shuffle(arr)\n",
    "            X_train = X_train[arr]\n",
    "            Y_train = Y_train[arr]\n",
    "            total_minibatch = int(np.ceil(X_train.shape[0]/batch_size))\n",
    "            for i in range(total_minibatch):\n",
    "                index = i * batch_size\n",
    "                X_train_sub = X_train[index:index+batch_size]\n",
    "                Y_train_sub = Y_train[index:index+batch_size]\n",
    "                grad = X_train_sub.transpose().dot(X_train_sub.dot(W) - Y_train_sub) + LAMBDA * W\n",
    "                W = W - learning_rate * grad\n",
    "            new_loss = self.compute_RSS(self.predict(W,X_train), Y_train)\n",
    "            if (np.abs(new_loss - last_loss) <= 1e-5):\n",
    "                break\n",
    "            last_loss = new_loss\n",
    "        return W\n",
    "\n",
    "    def predict(self, W, X_new):\n",
    "        X_new = np.array(X_new)\n",
    "        Y_new = X_new.dot(W)\n",
    "        return Y_new\n",
    "\n",
    "    def compute_RSS(self, Y_new, Y_predicted):\n",
    "        loss = 1. / Y_new.shape[0] * np.sum((Y_new - Y_predicted) ** 2)\n",
    "        return loss\n",
    "    \n",
    "    def get_the_best_LAMBDA(self, X_train, Y_train):\n",
    "        def cross_validation(num_folds, LAMBDA):\n",
    "            row_ids = np.array(range(X_train.shape[0]))\n",
    "            valid_ids = np.split(row_ids[:len(row_ids) - len(row_ids) % num_folds], num_folds)\n",
    "            valid_ids[-1] = np.append(valid_ids[-1], row_ids[len(row_ids) - len(row_ids) % num_folds:])\n",
    "            train_ids = [[k for k in row_ids if k not in valid_ids[i]] for i in range(num_folds)]\n",
    "            aver_RSS = 0\n",
    "            for i in range(num_folds):\n",
    "                # a[x].tolist() for x in b\n",
    "                valid_part = {'X': np.array([X_train[x] for x in valid_ids[i]]), 'Y': np.array([Y_train[x] for x in valid_ids[i]])}\n",
    "                train_part = {'X': np.array([X_train[x] for x in train_ids[i]]), 'Y': np.array([Y_train[x] for x in train_ids[i]])}\n",
    "                W = self.fit(train_part['X'], train_part['Y'], LAMBDA)\n",
    "                Y_predicted = self.predict(W, valid_part['X'])\n",
    "                aver_RSS += self.compute_RSS(valid_part['Y'], Y_predicted)\n",
    "            return aver_RSS / num_folds\n",
    "\n",
    "        def range_scan(best_LAMBDA, minimum_RSS, LAMBDA_values):\n",
    "            for current_LAMBDA in LAMBDA_values:\n",
    "                aver_RSS = cross_validation(num_folds=5, LAMBDA=current_LAMBDA)\n",
    "                if aver_RSS < minimum_RSS:\n",
    "                    best_LAMBDA = current_LAMBDA\n",
    "                    minimum_RSS = aver_RSS\n",
    "            return best_LAMBDA, minimum_RSS\n",
    "\n",
    "        best_LAMBDA, minimum_RSS = range_scan(best_LAMBDA = 0, minimum_RSS = 10000 ** 2, LAMBDA_values = range(50))\n",
    "\n",
    "        LAMBDA_values = [k * 1./ 1000 for k in range(max(0, (best_LAMBDA - 1) * 1000), (best_LAMBDA + 1) * 1000, 1)]\n",
    "\n",
    "        best_LAMBDA, minimum_RSS = range_scan(best_LAMBDA = best_LAMBDA, minimum_RSS = minimum_RSS, LAMBDA_values = LAMBDA_values)\n",
    "\n",
    "        return best_LAMBDA\n"
   ]
  },
  {
   "source": [
    "## 3. Get Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(\"../datasets/death-rates-data.txt\") as dataFile:\n",
    "        content = dataFile.read()\n",
    "    lines = content.split('\\n')\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:\n",
    "        temp = line.split()\n",
    "        feature = temp[1:-1]\n",
    "        output = float(temp[-1])\n",
    "        tempo = []\n",
    "        for e in feature:\n",
    "            tempo.append(float(e))\n",
    "\n",
    "        X.append(tempo)\n",
    "        Y.append(output)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "source": [
    "## 4. Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best LAMBDA: 0.002\n[877.39059783 921.33583769 931.7104582  893.81221771 993.93880571\n 894.54583255 932.43571582 891.59941659 912.15753609 923.87639342]\n[ 904.155  950.672  972.464  912.202  967.803  823.764 1003.502  895.696\n  911.817  954.442]\n1527.0698078028925\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    X, Y = get_data(path='../datasets/death-rates-data.txt')\n",
    "    X = normalize_and_add_ones(X)\n",
    "    X_train, Y_train = X[:50], Y[:50]\n",
    "    X_test, Y_test = X[50:], Y[50:]\n",
    "\n",
    "    ridge_regression = RidgeRegression()\n",
    "    best_LAMBDA = ridge_regression.get_the_best_LAMBDA(X_train, Y_train)\n",
    "    print(\"Best LAMBDA: {}\".format(best_LAMBDA))\n",
    "    W_learned = ridge_regression.fit(X_train=X_train, Y_train=Y_train, LAMBDA=best_LAMBDA)\n",
    "    Y_predicted = ridge_regression.predict(W=W_learned, X_new=X_test)\n",
    "    print(Y_predicted)\n",
    "    print(Y_test)\n",
    "    print(ridge_regression.compute_RSS(Y_new=Y_test, Y_predicted=Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}